<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Computer Vision Workshop</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>Welcome to the Advanced Computer Vision Workshop: Pixels to Paper</h1>
        <p>This repository is your gateway to mastering cutting-edge techniques in computer vision.</p>
    </header>
    
    <section class="topics">
        <h2>Topics Covered</h2>
        <ul>
            <li><a href="#">Intro to Computer Vision</a></li>
            <li><a href="#">Transformers</a></li>
            <li><a href="#">Diffusion Models</a></li>
            <li><a href="#">NeRFs (Neural Radiance Fields)</a></li>
            <li><a href="#">Gaussian Splatting</a></li>
            <li><a href="#">Custom Topics from Students</a></li>
            <li><a href="#">Introduction to Research Paper Writing</a></li>
            <li><a href="#">Networking</a></li>
        </ul>
    </section>

    <!-- Day-wise content as a table -->
    <section class="day-content">
        <h2>Day 1: Introduction to Computer Vision & Diffusion Models</h2>
        <table>
            <tr>
                <th>Session</th>
                <th>Description</th>
                <th>Links</th>
            </tr>
            <tr>
                <td>Intro to Computer Vision</td>
                <td>Unlock the fundamentals of computer vision and understand how machines perceive and interpret visual data.</td>
                <td><a href="https://docs.google.com/presentation/d/1-eBvg-jaY49qnAzZGF0YIAQTP0b9kr6zYEi2jaTWKTU/edit?usp=sharing">PPT Link</a></td>
            </tr>
            <tr>
                <td>Transformers</td>
                <td>Learn how Transformers are revolutionizing image processing and segmentation. Understand their core capabilities in visual models.</td>
                <td>Slides: <em>To Do</em></td>
            </tr>
            <tr>
                <td>Diffusion Models</td>
                <td>Explore the world of Diffusion Models and learn how they are changing image generation and restoration.</td>
                <td><a href="https://docs.google.com/presentation/d/1yYPugrsdYUut1hcbN96eXrzerQguvg2CTnJaPIk_lug/edit?usp=sharing">Diffusion Models Slides</a></td>
            </tr>
            <tr>
                <td>Basic Diffusion</td>
                <td>Hands-on demo with a basic diffusion model.</td>
                <td><a href="https://colab.research.google.com/drive/1ju1SC2vPESGS8BzQ46iBkx8ZHQxLJxAM?usp=sharing">Colab Link</a></td>
            </tr>
            <tr>
                <td>Stable Diffusion</td>
                <td>Deep dive into Stable Diffusion for more refined and stable image generation.</td>
                <td><a href="https://colab.research.google.com/drive/1pdS8vHiDVz0ZJHi9FBrUPo8bGS4MpmI7?usp=sharing">Colab Link</a></td>
            </tr>
            <tr>
                <td>Image Inpainting</td>
                <td>Learn how to use diffusion models for inpainting (restoring missing parts of an image).</td>
                <td><a href="https://colab.research.google.com/drive/11h596vX1vF3a9pqwDC5KWBxldVy_-0G-?usp=sharing">Colab Link</a></td>
            </tr>
        </table>
    </section>
    
    <section class="day-content">
        <h2>Day 2: NeRF & Gaussian Splatting</h2>
        <table>
            <tr>
                <th>Session</th>
                <th>Description</th>
                <th>Links</th>
            </tr>
            <tr>
                <td>NeRF</td>
                <td>Master Neural Radiance Fields (NeRF), a technique for creating photorealistic 3D scenes from 2D images.</td>
                <td>Slides: <em>To Do</em></td>
            </tr>
            <tr>
                <td>NeRF Colab</td>
                <td>Hands-on exercise to create 3D scenes using NeRF.</td>
                <td><a href="https://colab.research.google.com/drive/12fC9EHPKY2f-xbFXjl9zZJY0yxcDdgUd?usp=sharing">NeRF Colab Link</a></td>
            </tr>
            <tr>
                <td>Gaussian Splatting</td>
                <td>Explore Gaussian Splatting to improve point cloud representation and 3D reconstruction accuracy.</td>
                <td><a href="https://docs.google.com/presentation/d/1OKtE_RMAl_JY3t2DGcpUf0cb-tvRH6W0YzRLrIj501w/edit?usp=sharing">Gaussian Splatting Slides</a></td>
            </tr>
            <tr>
                <td>Gaussian Splatting Colab</td>
                <td>Work through hands-on examples for Gaussian Splatting in this practical session.</td>
                <td><a href="https://colab.research.google.com/drive/1odB2i8GnE7F75cUl0vP10WRA34ETSRvp?usp=sharing">Colab Link</a></td>
            </tr>
        </table>
    </section>

    <section class="day-content">
        <h2>Day 3: Custom Topics from Students & Networking</h2>
        <table>
            <tr>
                <th>Session</th>
                <th>Description</th>
                <th>Links</th>
            </tr>
            <tr>
                <td>Custom Topics</td>
                <td>Explore unique topics proposed by students and gain insights into real-world applications of computer vision.</td>
                <td><a href="https://docs.google.com/presentation/d/1h6a7pGW3EGEgV7cZockN61rPUf_4mBqdXhbVpTPyPnE/edit?usp=sharing">Detection Models Slides</a></td>
            </tr>
            <tr>
                <td>Detection Models</td>
                <td>Hands-on with detection models, showcasing how to apply them in real-world scenarios.</td>
                <td><a href="https://colab.research.google.com/drive/1t84sqWNJj1xJdkUviSLofK9M9bVuiEB6?usp=sharing">Detection Models Colab Link</a></td>
            </tr>
            <tr>
                <td>CVAT</td>
                <td>Explore CVAT (Computer Vision Annotation Tool), a powerful tool for annotating data for training vision models.</td>
                <td><a href="https://www.cvat.ai/">CVAT Website</a></td>
            </tr>
            <tr>
                <td>CLIP Inference</td>
                <td>Learn how CLIP (Contrastive Language-Image Pretraining) is used to analyze images and text together for powerful multimodal applications.</td>
                <td><a href="https://colab.research.google.com/drive/1-xf2Uq3nzhwu37iKwnz0ScTYcJksmZc2?usp=sharing">CLIP Tutorial Colab</a></td>
            </tr>
        </table>
    </section>
    
    <section class="networking">
        <h2>Networking</h2>
        <h3>SaiSriTeja</h3>
        <ul>
            <li><a href="https://www.linkedin.com/in/saisriteja/">LinkedIn</a></li>
            <li><a href="https://saisritejakuppa.github.io/">Personal Website</a></li>
        </ul>
        
        <h3>Vinayak Gupta</h3>
        <ul>
            <li><a href="https://www.linkedin.com/in/vinayak-gupta-9b5795145/">LinkedIn</a></li>
            <li><a href="https://vinayak-vg.github.io/">Personal Website</a></li>
        </ul>
    </section>
    
    <footer>
        <p>&copy; 2025 Advanced Computer Vision Workshop</p>
    </footer>
</body>
</html>
